# RLTS

This is the implementation of our paper "Trajectory Simplification with Reinforcement Learning" (ICDE 2021).

## Requirements

* Linux Ubuntu OS (22.04 is tested)
* Python >= 3.8 (Anaconda3 is recommended and 3.1 is tested)
* Tensorflow (2.1.0 is tested)

Please refer to the source code to install the required packages that has not been installed in your environment such as matplotlib in Python for visualization. You can install packages with conda in a shell as

```
conda install matplotlib
```

## Dataset & Preprocessing

Download & unzip the dataset [Geolife](http://research.microsoft.com/en-us/downloads/b16d359d-d164-469e-9fd4-daa38f2b2e13/) and put its folder into `./TrajData`. Note that the input data generated by [`preprocess.py`](preprocess.py) will also be stored in this folder.

```
python preprocess.py
```

## Running Procedures

### Hyperparameters
There are several hyperparameters in [`rl_brain_upgraded.py`](./online-rlts/rl_brain_upgraded.py), you may try to turn these parameters for a better performance when training, including `units = 20`, `activation = tf.nn.tanh`, `learning_rate = 0.001` `reward_decay = 0.99`.

### Training

Run [`rl_main_pg_one.py`] the generated models will be stored in the folder `./save` automatically, and you can pick one model with the best performance on the validation data as your model from them.

```
python rl_main_pg_one.py
```
Here, we provide an interface [`RL.load(checkpoint)`](./online-rlts/rl_brain.py), and you can load an intermediate model to continue the training from the checkpoint, which saves your efforts caused by some unexpected exceptions and no need to train again.
In addition, we implemented an incremental computation for reward update in [`rl_env_inc_one.py`], which offers a very fast efficiency for the training, and you may refer the figure [`inc.png`] to get more details.
After your model is trained, we provide a fast interface called [`quick_time_action(observation)`], which replaces the function of DL tool and implements the NN forward more efficiently.

### Error Measurements
We implemented four mainstream error measurements of trajectory simplification in [`data_utils_muti.py`], including SED [`sed_op`], [`sed_error`], PED [`ped_op`], [`ped_error`], DAD [`dad_op`], [`dad_error`], and SAD [`speed_op`], [`speed_error`], where '_op' denotes the error on an anchor segment, and "_error" denotes the error between the orignal trajectory and its simplified trajectory. More details can be found in the paper. The default error measurement is SED, if you want to test more measurements, just simply replace the corresponding function name in [`rl_env_inc_one.py`].

### Visualization

We provide an interface [`data_utils.draw(ori_traj, sim_traj, label='sed')`](./online-rlts/data_utils_muti.py) to visualize the simplified trajectory [`vis.png`](./online-rlts/vis.png), you can also use it to observe the model performance during the training or comment it in the codes for your purpose. Note that this parts is supported by matplotlib in Python 3.6.
```
final_error = F.draw(self.ori_traj_set[episode], sim_traj)
```

### Evaluation

You can directly run the [`rl_evaluate_one.py`]once you obtain the trained model.

```
python rl_evaluate_one.py
```
Similarly, you can set a skipping step `skip_size` to train the RLTS-Skip model, which provides a trade-off between the effectiveness and efficiency.

### Interpolation

Interpolation can be done directly with n-dimension code, supporting 2-n dimensional data
Code stored in RLTS-one/interpolation/N_dimension.py

1. Input format: n tracks in txt format, each one is in the form of [timestamp longitude/latitude/other information].

2. How to execute the code: directly input the name of the input file.

3. Output format: output the interpolated trajectory routes, the code will be automatically saved to a txt file.


### How to use the data process python code

preprocess_muti.py preprocess_muti.py is to cut Geolife's trajectory data into single dimensions for use by RLTS

mopsi_preprocess.py is to cut the mopsi trajectory data (3D) into single dimensions for use by RLTS

compressRate.py measures the error between the compressed trajectory data and the original trajectory.The usage is commented in the source code.

process_height.py is to deal with the mopsi dataset, the height of the data all 0 cases, such data into the RLTS will be overflow, and not good to modify, so directly through this to remove

